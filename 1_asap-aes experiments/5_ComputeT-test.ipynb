{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset1_ASAP_AES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import os\n",
    "# Folder path containing the CSV files\n",
    "folder_path = r'E:\\Research work\\assessment checker research\\asap-aes\\results_gpt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Raters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of EssaySet1 is 1783\n",
      "EssaySet1 Domain1; t-statistic: -0.46\n",
      "EssaySet1  Domain1; p-value: 6.46e-01\n",
      "\n",
      "Size of EssaySet2 is 1800\n",
      "EssaySet2 Domain1; t-statistic: -1.9\n",
      "EssaySet2  Domain1; p-value: 5.80e-02\n",
      "\n",
      "Size of EssaySet2 is 1800\n",
      "EssaySet2 Domain2; t-statistic: 0.31\n",
      "EssaySet2  Domain2; p-value: 7.58e-01\n",
      "\n",
      "Size of EssaySet3 is 1726\n",
      "EssaySet3 Domain1; t-statistic: 3.39\n",
      "EssaySet3  Domain1; p-value: 7.19e-04\n",
      "\n",
      "Size of EssaySet4 is 1771\n",
      "EssaySet4 Domain1; t-statistic: 0.3\n",
      "EssaySet4  Domain1; p-value: 7.67e-01\n",
      "\n",
      "Size of EssaySet5 is 1805\n",
      "EssaySet5 Domain1; t-statistic: -0.03\n",
      "EssaySet5  Domain1; p-value: 9.73e-01\n",
      "\n",
      "Size of EssaySet6 is 1800\n",
      "EssaySet6 Domain1; t-statistic: 0.72\n",
      "EssaySet6  Domain1; p-value: 4.71e-01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loop over each file from EssaySet1 to EssaySet8\n",
    "for i in range(1, 7):\n",
    "    file_name = f'EssaySet{i}_assessment_results_by_rubric.csv'\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    # Read the CSV file\n",
    "    if os.path.exists(file_path):\n",
    "        data = pd.read_csv(file_path)       \n",
    "        # print(f\"Checking missing values in EssaySet{i}...\")\n",
    "        # print(\"Empty records\", data['domain1_Score_gemini'].isnull().sum())\n",
    "        data = data[['rater1_domain1', 'rater2_domain1']].dropna()\n",
    "\n",
    "        # Perform paired t-test\n",
    "        t_statistic, p_value = stats.ttest_rel(data['rater1_domain1'], data['rater2_domain1'])\n",
    "        print(f\"Size of EssaySet{i} is {len(data)}\")\n",
    "        print(f\"EssaySet{i} Domain1; t-statistic: {round(t_statistic,2)}\")\n",
    "        print(f\"EssaySet{i}  Domain1; p-value: {p_value:.2e}\")\n",
    "        print()\n",
    "        if i==2:# print(\"Empty records\", data['domain1_Score_gemini'].isnull().sum())\n",
    "            data = pd.read_csv(file_path)\n",
    "            data = data[['rater1_domain2', 'rater2_domain2']].dropna()\n",
    "\n",
    "            # Perform paired t-test\n",
    "            t_statistic, p_value = stats.ttest_rel(data['rater1_domain2'], data['rater2_domain2'])\n",
    "            print(f\"Size of EssaySet{i} is {len(data)}\")\n",
    "            print(f\"EssaySet{i} Domain2; t-statistic: {round(t_statistic,2)}\")\n",
    "            print(f\"EssaySet{i}  Domain2; p-value: {p_value:.2e}\")\n",
    "            print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT T-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of EssaySet1 is  1536\n",
      "EssaySet1 Domain1; t-statistic: 52.62\n",
      "EssaySet1  Domain1; p-value: 0.00e+00\n",
      "\n",
      "Size of EssaySet2 is  1726\n",
      "EssaySet2 Domain1; t-statistic: 7.54\n",
      "EssaySet2  Domain1; p-value: 7.78e-14\n",
      "\n",
      "Size of EssaySet2 is 1800\n",
      "EssaySet2 Domain2; t-statistic: nan\n",
      "EssaySet2  Domain2; p-value: nan\n",
      "\n",
      "Size of EssaySet3 is  1691\n",
      "EssaySet3 Domain1; t-statistic: 23.79\n",
      "EssaySet3  Domain1; p-value: 4.19e-108\n",
      "\n",
      "Size of EssaySet4 is  1732\n",
      "EssaySet4 Domain1; t-statistic: -10.1\n",
      "EssaySet4  Domain1; p-value: 2.40e-23\n",
      "\n",
      "Size of EssaySet5 is  1804\n",
      "EssaySet5 Domain1; t-statistic: -10.71\n",
      "EssaySet5  Domain1; p-value: 5.24e-26\n",
      "\n",
      "Size of EssaySet6 is  1776\n",
      "EssaySet6 Domain1; t-statistic: -11.89\n",
      "EssaySet6  Domain1; p-value: 1.97e-31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Folder path containing the CSV files\n",
    "folder_path = r'E:\\Research work\\assessment checker research\\asap-aes\\results_gpt'\n",
    "\n",
    "# Loop over each file from EssaySet1 to EssaySet8\n",
    "for i in range(1, 7):\n",
    "    file_name = f'EssaySet{i}_assessment_results_by_rubric.csv'\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    # Read the CSV file\n",
    "    if os.path.exists(file_path):\n",
    "        data = pd.read_csv(file_path)\n",
    "        if i==1:\n",
    "            data['domain1_score']= data['domain1_score']//2\n",
    "        if 'domain1_Point_gpt' in data.columns:\n",
    "            data['domain1_Score_gpt'] = data['domain1_Score_gpt'].fillna(data['domain1_Point_gpt'])\n",
    "            \n",
    "        # print(f\"Checking missing values in EssaySet{i}...\")\n",
    "        # print(data[['domain1_score', 'domain1_Score_gemini']].isnull().sum())\n",
    "        data = data[['domain1_score', 'domain1_Score_gpt']].dropna()\n",
    "\n",
    "        # Perform paired t-test\n",
    "        t_statistic, p_value = stats.ttest_rel(data['domain1_score'], data['domain1_Score_gpt'])\n",
    "        print(f\"Size of EssaySet{i} is  {len(data)}\")\n",
    "        print(f\"EssaySet{i} Domain1; t-statistic: {round(t_statistic,2)}\")\n",
    "        print(f\"EssaySet{i}  Domain1; p-value: {p_value:.2e}\")\n",
    "        if i==2:# print(\"Empty records\", data['domain1_Score_gemini'].isnull().sum())\n",
    "            data = pd.read_csv(file_path)\n",
    "            if 'domain2_Point_gpt' in data.columns:            \n",
    "                data['domain2_Score_gpt'] = data['domain2_Score_gpt'].fillna(data['domain2_Point_gpt'])\n",
    "            \n",
    "            # Perform paired t-test\n",
    "            t_statistic, p_value = stats.ttest_rel(data['domain2_score'], data['domain2_Score_gpt'])\n",
    "            print()\n",
    "            print(f\"Size of EssaySet{i} is {len(data)}\")\n",
    "            print(f\"EssaySet{i} Domain2; t-statistic: {round(t_statistic,2)}\")\n",
    "            print(f\"EssaySet{i}  Domain2; p-value: {p_value:.2e}\")\n",
    "\n",
    "        print()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemini T-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of EssaySet1 is 1685\n",
      "EssaySet1 Domain1; t-statistic: 99.09\n",
      "EssaySet1  Domain1; p-value: 0.00e+00\n",
      "\n",
      "Size of EssaySet2 is 1525\n",
      "EssaySet2 Domain1; t-statistic: -8.36\n",
      "EssaySet2  Domain1; p-value: 1.34e-16\n",
      "\n",
      "Size of EssaySet2 is 1524\n",
      "EssaySet2 Domain2; t-statistic: 46.37\n",
      "EssaySet2  Domain2; p-value: 1.96e-293\n",
      "\n",
      "Size of EssaySet3 is 1544\n",
      "EssaySet3 Domain1; t-statistic: 15.26\n",
      "EssaySet3  Domain1; p-value: 4.20e-49\n",
      "\n",
      "Size of EssaySet4 is 1557\n",
      "EssaySet4 Domain1; t-statistic: 0.84\n",
      "EssaySet4  Domain1; p-value: 4.01e-01\n",
      "\n",
      "Size of EssaySet5 is 1277\n",
      "EssaySet5 Domain1; t-statistic: 16.73\n",
      "EssaySet5  Domain1; p-value: 5.78e-57\n",
      "\n",
      "Size of EssaySet6 is 1320\n",
      "EssaySet6 Domain1; t-statistic: 4.08\n",
      "EssaySet6  Domain1; p-value: 4.71e-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folder_path = r'E:\\Research work\\assessment checker research\\asap-aes\\results_gemini'\n",
    "# Loop over each file from EssaySet1 to EssaySet8\n",
    "for i in range(1, 7):\n",
    "    file_name = f'EssaySet{i}_assessment_results_by_rubric.csv'\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    # Read the CSV file\n",
    "    if os.path.exists(file_path):\n",
    "        data = pd.read_csv(file_path)\n",
    "        if i==1:\n",
    "            data['domain1_score']= data['domain1_score']//2\n",
    "        if 'domain1_Point_gemini' in data.columns:            \n",
    "            data['domain1_Score_gemini'] = data['domain1_Score_gemini'].fillna(data['domain1_Point_gemini'])\n",
    "            \n",
    "        # print(f\"Checking missing values in EssaySet{i}...\")\n",
    "        # print(\"Empty records\", data['domain1_Score_gemini'].isnull().sum())\n",
    "        data = data[['domain1_score', 'domain1_Score_gemini']].dropna()\n",
    "\n",
    "        # Perform paired t-test\n",
    "        t_statistic, p_value = stats.ttest_rel(data['domain1_score'], data['domain1_Score_gemini'])\n",
    "        print(f\"Size of EssaySet{i} is {len(data)}\")\n",
    "        print(f\"EssaySet{i} Domain1; t-statistic: {round(t_statistic,2)}\")\n",
    "        print(f\"EssaySet{i}  Domain1; p-value: {p_value:.2e}\")\n",
    "\n",
    "        if i==2:# print(\"Empty records\", data['domain1_Score_gemini'].isnull().sum())\n",
    "            data = pd.read_csv(file_path)\n",
    "            if 'domain2_Point_gemini' in data.columns:            \n",
    "                data['domain2_Score_gemini'] = data['domain2_Score_gemini'].fillna(data['domain2_Point_gemini'])\n",
    "            \n",
    "            data = data[['domain2_score', 'domain2_Score_gemini']].dropna()\n",
    "            # Perform paired t-test\n",
    "            t_statistic, p_value = stats.ttest_rel(data['domain2_score'], data['domain2_Score_gemini'])\n",
    "            print()\n",
    "            print(f\"Size of EssaySet{i} is {len(data)}\")\n",
    "            print(f\"EssaySet{i} Domain2; t-statistic: {round(t_statistic,2)}\")\n",
    "            print(f\"EssaySet{i}  Domain2; p-value: {p_value:.2e}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Computatation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of EssaySet1 is 1536\n",
      "t-value: 52.6185\n",
      "Degrees of freedom: 1535\n",
      "\n",
      "Size of EssaySet2 is 1726\n",
      "t-value: 7.5361\n",
      "Degrees of freedom: 1725\n",
      "\n",
      "Size of EssaySet2 Domain2 is 1575\n",
      "t-value: 62.17\n",
      "Degrees of freedom: 1574\n",
      "\n",
      "Size of EssaySet3 is 1691\n",
      "t-value: 23.7854\n",
      "Degrees of freedom: 1690\n",
      "\n",
      "Size of EssaySet4 is 1732\n",
      "t-value: -10.1007\n",
      "Degrees of freedom: 1731\n",
      "\n",
      "Size of EssaySet5 is 1804\n",
      "t-value: -10.7134\n",
      "Degrees of freedom: 1803\n",
      "\n",
      "Size of EssaySet6 is 1776\n",
      "t-value: -11.8917\n",
      "Degrees of freedom: 1775\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Manual computation\n",
    "\n",
    "import numpy as np\n",
    "# Folder path containing the CSV files\n",
    "folder_path = r'E:\\Research work\\assessment checker research\\asap-aes\\results_gpt'\n",
    "\n",
    "# Loop over each file from EssaySet1 to EssaySet8\n",
    "for i in range(1, 7):\n",
    "    file_name = f'EssaySet{i}_assessment_results_by_rubric.csv'\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    # Read the CSV file\n",
    "    if os.path.exists(file_path):\n",
    "        data = pd.read_csv(file_path)\n",
    "        if i==1:\n",
    "            data['domain1_score']= data['domain1_score']//2\n",
    "        if 'domain1_Point_gpt' in data.columns:\n",
    "            data['domain1_Score_gpt'] = data['domain1_Score_gpt'].fillna(data['domain1_Point_gpt'])\n",
    "            \n",
    "        # print(f\"Checking missing values in EssaySet{i}...\")\n",
    "        # print(data[['domain1_score', 'domain1_Score_gpt']].isnull().sum())\n",
    "        data = data[['domain1_score', 'domain1_Score_gpt']].dropna()\n",
    "\n",
    "        # Calculate differences between paired scores\n",
    "        differences = data['domain1_score'] - data['domain1_Score_gpt']\n",
    "\n",
    "        # Compute mean and standard deviation of differences\n",
    "        mean_diff = np.mean(differences)\n",
    "        std_diff = np.std(differences, ddof=1)  # ddof=1 for sample standard deviation\n",
    "        n = len(differences)\n",
    "\n",
    "        # Calculate the t-value\n",
    "        t_value = mean_diff / (std_diff / np.sqrt(n))\n",
    "        df = n - 1\n",
    "        print(f\"Size of EssaySet{i} is {len(data)}\")\n",
    "        print(\"t-value:\", round(t_value, 4))\n",
    "        print(\"Degrees of freedom:\", df)\n",
    "        print()\n",
    "        if i==2:\n",
    "            data = pd.read_csv(file_path)\n",
    "            data = data[['domain2_score', 'domain2_Score_gpt']].dropna()\n",
    "            if 'domain2_Point_gpt' in data.columns:\n",
    "                data['domain2_Score_gpt'] = data['domain2_Score_gpt'].fillna(data['domain2_Point_gpt'])\n",
    "            # Calculate differences between paired scores\n",
    "            differences = data['domain2_score'] - data['domain2_Score_gpt']\n",
    "\n",
    "            # Compute mean and standard deviation of differences\n",
    "            mean_diff = np.mean(differences)\n",
    "            std_diff = np.std(differences, ddof=1)  # ddof=1 for sample standard deviation\n",
    "            n = len(differences)\n",
    "\n",
    "            # Calculate the t-value\n",
    "            t_value = mean_diff / (std_diff / np.sqrt(n))\n",
    "            df = n - 1\n",
    "            print(f\"Size of EssaySet{i} Domain2 is {len(data)}\")\n",
    "            print(\"t-value:\", round(t_value, 2))\n",
    "            print(\"Degrees of freedom:\", df)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset2_Learning Agency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score                   0\n",
      "Holistic Score_GPT    343\n",
      "dtype: int64\n",
      "Size of Dataset 4846\n",
      "t-statistic: 1.03\n",
      "p-value: 0.3\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the provided Excel file\n",
    "file_path = 'learning-agency-lab-automated-essay-scoring-2/results_gpt/Holistic_assessment_results_by_rubric.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# NULL VAlues\n",
    "\n",
    "data['Holistic Score_GPT'] = data['Holistic Score_GPT'].fillna(data['Holistic Rating_GPT'])\n",
    "    \n",
    "print(data[['score', 'Holistic Score_GPT']].isnull().sum())\n",
    "data = data[['score', 'Holistic Score_GPT']].dropna()\n",
    "\n",
    "from scipy import stats\n",
    "# Perform paired t-test\n",
    "t_statistic, p_value = stats.ttest_rel(data['score'], data['Holistic Score_GPT'])\n",
    "print(\"Size of Dataset\", len(data))\n",
    "print(\"t-statistic:\", round(t_statistic,2))\n",
    "print(\"p-value:\", round(p_value,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score             0\n",
      "Score_gemini    115\n",
      "dtype: int64\n",
      "Size of Dataset 5074\n",
      "t-statistic: -0.69\n",
      "p-value: 0.49\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the provided Excel file\n",
    "file_path = 'learning-agency-lab-automated-essay-scoring-2/results_gemini/Holistic_assessment_results_by_rubric.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "data.head()\n",
    "\n",
    "# NULL VAlues\n",
    "print(data[['score', 'Score_gemini']].isnull().sum())\n",
    "data = data[['score', 'Score_gemini']].dropna()\n",
    "\n",
    "from scipy import stats\n",
    "# Perform paired t-test\n",
    "t_statistic, p_value = stats.ttest_rel(data['score'], data['Score_gemini'])\n",
    "print(\"Size of Dataset\", len(data))\n",
    "print(\"t-statistic:\", round(t_statistic,2))\n",
    "print(\"p-value:\", round(p_value,2))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute T-value manualy\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-value: 0.69\n",
      "Degrees of freedom: 5073\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Calculate differences between paired scores\n",
    "differences = data['Score_gemini'] - data['score']\n",
    "\n",
    "# Compute mean and standard deviation of differences\n",
    "mean_diff = np.mean(differences)\n",
    "std_diff = np.std(differences, ddof=1)  # ddof=1 for sample standard deviation\n",
    "n = len(differences)\n",
    "\n",
    "# Calculate the t-value\n",
    "t_value = mean_diff / (std_diff / np.sqrt(n))\n",
    "df = n - 1\n",
    "\n",
    "print(\"t-value:\", round(t_value,2))\n",
    "print(\"Degrees of freedom:\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
